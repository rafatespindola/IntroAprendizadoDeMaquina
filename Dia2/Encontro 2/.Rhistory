demo()
?sin
x <- seq(-3, 7, by = 1/8)
tx <- cbind(x, cos(pi*x), cospi(x), sin(pi*x), sinpi(x),
tan(pi*x), tanpi(x), deparse.level=2)
op <- options(digits = 4, width = 90) # for nice formatting
head(tx)
tx[ (x %% 1) %in% c(0, 0.5) ,]
options(op)
plot(x)
clear
print("olÃ¡")
library(caTools)
library(RWeka)
library(caTools)
library(RWeka)
install.packages("RWeka")
library(RWeka)
install.packages("rJava")
library(rJava)
library("RWekajars", lib.loc="~/R/win-library/3.4")
library("reshape2", lib.loc="~/R/win-library/3.4")
detach("package:RWekajars", unload=TRUE)
detach("package:reshape2", unload=TRUE)
library("lava", lib.loc="~/R/win-library/3.4")
detach("package:lava", unload=TRUE)
library("munsell", lib.loc="~/R/win-library/3.4")
detach("package:munsell", unload=TRUE)
install.packages('rJava')
library(rJava)
library(RWeka)
library(RWekajars)
library(RWeka)
install.packages("RWeka")
install.packages('caTools')
library(RWeka)
install.packages("rJava")
install.packages("rJava")
library(rJava)
library(rJava)
setwd("C:/Users/neto/Dropbox/Curso ML Ministrados/Curso ML Embrapii/Encontro 1")
subject_name <- c("John Doe", "Jane Doe", "Steve Graves")
temperature <- c(98.1, 98.6, 101.4)
flu_status <- c(FALSE, FALSE, TRUE)
temperature[2]
temperature[2:3]
temperature[-2]
temperature[c(TRUE, TRUE, TRUE)]
temperature[c(TRUE, FALSE, TRUE)]
gender <- factor(c("MALE", "FEMALE", "MALE"))
gender
blood <- factor(c("O", "AB", "A"),
levels = c("A", "B", "AB", "O"))
blood
symptoms <- factor(c("SEVERE", "MILD", "MODERATE"),
levels = c("MILD", "MODERATE", "SEVERE"),
ordered = TRUE)
symptoms
symptoms >= "MODERATE"
symptoms > "MODERATE"
subject_name[1]
temperature[1]
flu_status[1]
gender[1]
blood[1]
symptoms[1]
subject1 <- list(fullname = subject_name[1],
temperature = temperature[1],
flu_status = flu_status[1],
gender = gender[1],
blood = blood[1],
symptoms = symptoms[1])
subject1
subject1[2]
subject1[[2]]
subject1$temperature
gg = subject1[2]
gg
gg = subject1[[2]]
subject1[c("temperature", "flu_status")]
ddd=subject1[c("temperature", "flu_status")]
pt_data <- data.frame(subject_name, temperature, flu_status, gender,
blood, symptoms, stringsAsFactors = FALSE)
View(pt_data)
pt_data[c("temperature", "flu_status")]
pt_data[2:3]
pt_data[ , ]
pt_data[c(1, 3), c("temperature", "gender")]
pt_data[-2, c(-1, -3, -5, -6)]
setwd("C:/Users/neto/Dropbox/Curso ML Ministrados/Arquivos_Livro_MLwR/Machine Learning with R (2nd Ed.)/Chapter 03")
wbcd <- read.csv("wisc_bc_data.csv", stringsAsFactors = FALSE)
View(wbcd)
wbcd <- wbcd[-1]
View(wbcd)
table(wbcd$diagnosis)
View(wbcd)
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B", "M"),
labels = c("Benign", "Malignant"))
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 1)
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 2)
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 1)
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 2)
round(prop.table(table(wbcd$diagnosis)) , digits = 2)
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
summary(wbcd)
View(wbcd)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
normalize(c(1, 2, 3, 4, 5))
normalize(c(10, 20, 30, 40, 50))
wbcd_n <- (apply(wbcd[2:31], normalize)
d
wbcd_n <- (lapply(wbcd[2:31], normalize))
wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))
summary(wbcd_n$area_mean)
wbcd_train <- wbcd_n[1:469, ]
wbcd_test <- wbcd_n[470:569, ]
View(wbcd_train)
View(wbcd)
wbcd_train <- wbcd_n[1:469, ]
wbcd_test <- wbcd_n[470:569, ]
View(wbcd_train)
wbcd_train_labels <- wbcd[1:469, 1]
wbcd_test_labels <- wbcd[470:569, 1]
library(class)
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k = 21)
library(gmodels)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq = FALSE)
install.packages("gmodels")
library(gmodels)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq = FALSE)
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k = 1)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq = FALSE)
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k = 21)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq = TRUE)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq = FALSE)
setwd("C:/Users/neto/OneDrive/Cursos/Machine Learning A-Z/Part 3 - Classification/Section 15 - K-Nearest Neighbors (K-NN)")
dataset = read.csv('Social_Network_Ads.csv')
View(dataset)
dataset = dataset[3:5]
View(dataset)
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
setwd("C:/Users/neto/Dropbox/Curso ML Ministrados/Curso ML Embrapii/Encontro 1")
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
str(sms_raw)
sms_raw$type <- factor(sms_raw$type)
str(sms_raw)
str(sms_raw$type)
table(sms_raw$type)
library(tm)
install.packages("tm")
library(tm)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2], as.character)
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:3], as.character)
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers) # remove numbers
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # remove stop words
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation) # remove punctuation
library(SnowballC)
install.packages("SnowballC")
library(SnowballC)
wordStem(c("learn", "learned", "learning", "learns"))
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # eliminate unneeded whitespace
lapply(sms_corpus[1:3], as.character)
lapply(sms_corpus_clean[1:3], as.character)
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels  <- sms_raw[4170:5559, ]$type
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
install.packages("wordcloud")
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
spam <- subset(sms_raw, type == "spam")
ham  <- subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train, 0.999)
findFreqTerms(sms_dtm_train, 5)
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
str(sms_freq_words)
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
install.packages("e1071")
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
setwd("C:/Users/neto/Desktop/Encontro 1")
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
sms_raw$type <- factor(sms_raw$type)
str(sms_raw$type)
table(sms_raw$type)
library(tm)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:3], as.character)
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers) # remove numbers
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # remove stop words
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation) # remove punctuation
library(SnowballC)
wordStem(c("learn", "learned", "learning", "learns"))
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # eliminate unneeded whitespace
lapply(sms_corpus[1:3], as.character)
lapply(sms_corpus_clean[1:3], as.character)
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
str(sms_raw)
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers) # remove numbers
lapply(sms_corpus[1:3], as.character)
lapply(sms_corpus_clean[1:3], as.character)
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # remove stop words
lapply(sms_corpus[1:3], as.character)
lapply(sms_corpus_clean[1:3], as.character)
stopwords()
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation) # remove punctuation
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # eliminate unneeded whitespace
lapply(sms_corpus[1:3], as.character)
lapply(sms_corpus_clean[1:3], as.character)
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels  <- sms_raw[4170:5559, ]$type
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
aa = sms_raw$type
aa = sms_raw[1:4169, ]$type
aa
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
spam <- subset(sms_raw, type == "spam")
ham  <- subset(sms_raw, type == "ham")
wordcloud(sms_corpus_clean, min.freq = 500, random.order = FALSE)
wordcloud(sms_corpus_clean, min.freq = 100, random.order = FALSE)
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(spam$text, max.words = 4, scale = c(3, 0.5))
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(spam$text, max.words = 5, scale = c(3, 0.5))
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
stopwords()
findFreqTerms(sms_dtm_train, 5)
findFreqTerms(sms_dtm_train, 5)
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
str(sms_freq_words)
aa = c(a, b, c, d, e)
aa = c("a", "b", "c", "d", "e")
aa
aaa = c("a", "b", "c")
sss = aa[ , aaa]
View(sms_raw)
sms_freq_words
sms_freq_words(1:3)
str(sms_freq_words)
sss = aa[ , aaa]
sss = aaa[ , aa]
aaa
aa
sss = aa[ , 1:2]
sss = aa[ , 1]
aa[1:2]
aa[aaa]
aa[a]
aa["a"]
aa[1,]
aa[aaa]
aa[3]
aaa
aa["c"]
aa[""]
aa[]
ccc=sms_dtm_train[ , 1]
ccc
ccc=sms_dtm_train[ , "can"]
ccc
ccc=sms_dtm_train[ , 1]
ccc=sms_dtm_train[ , 2]
ccc=sms_dtm_train[ , 3]
ccc=sms_dtm_train[ , 100]
ccc=sms_dtm_train[ , "affair"]
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
str(sms_freq_words)
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
library(e1071)
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
sms_test_pred <- predict(sms_classifier, sms_test)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
library(gmodels)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
sms_classifier2 <- naiveBayes(sms_train, sms_train_labels, laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
CrossTable(sms_test_pred2, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
setwd("C:/Users/neto/Dropbox/Curso ML Ministrados/Curso ML Embrapii/Encontro 2")
insurance <- read.csv("insurance.csv", stringsAsFactors = TRUE)
hist(insurance$expenses)
setwd("C:/Users/neto/Dropbox/Curso ML Ministrados/Curso ML Embrapii/Encontro 1")
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
sms_raw$type <- factor(sms_raw$type)
library(tm)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers) # remove numbers
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # remove stop words
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation) # remove punctuation
library(SnowballC)
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # eliminate unneeded whitespace
lapply(sms_corpus[1:3], as.character)
lapply(sms_corpus_clean[1:3], as.character)
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels  <- sms_raw[4170:5559, ]$type
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
findFreqTerms(sms_dtm_train, 5)
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
sms_test_pred <- predict(sms_classifier, sms_test)
sms_test_pred
sms_test
View(sms_test)
aaa = sms_test[1,]
sms_test_pred_1 <- predict(sms_classifier, aaa)
sms_test_pred_1
aaa = sms_test[,1]
sms_test_pred_1 <- predict(sms_classifier, aaa)
sms_test_pred_1
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
aaa = sms_test[1,1]
aaa
aaa = sms_test[1,]
sms_test_pred_1 <- predict(sms_classifier, aaa)
sms_test_pred_1
aaa = sms_test[1:2,]
aaa = sms_test[1,]
aaa = sms_test[1:2,]
sms_test_pred_1 <- predict(sms_classifier, aaa)
sms_test_pred_1 <- predict(sms_classifier, aaa)
sms_test_pred_1
aaa = sms_test[,1:2]
sms_test_pred_1 <- predict(sms_classifier, aaa)
sms_test_pred_1
aaa = sms_test[1:2,]
sms_test_pred_1 <- predict(sms_classifier, aaa)
sms_test_pred_1
aaa = sms_test[1 22,]
aaa = sms_test[1;22,]
aaa = sms_test[c(1,22),]
sms_test_pred_1 <- predict(sms_classifier, aaa)
aaa = sms_test[1;22,]
sms_test_pred_1
aaa = sms_test[1,]
aaa = as.dataframe(sms_test[1,])
as.data.frame(sms_test[1,])
aaa =as.data.frame(sms_test[1,])
sms_test_pred_1 <- predict(sms_classifier, aaa)
sms_test_pred_1
aaa =as.data.frame(sms_test[,1])
aaa =as.data.frame(sms_test[1,1])
aaa =as.data.frame(sms_test[1,)
aaa =as.data.frame(sms_test[1,])
aaa =as.data.frame(sms_test[,1])
aaa =as.data.frame(sms_test[1,])
aaa =as.data.frame(sms_test[,1])
aaa = sms_test[1:2,]
setwd("C:/Users/neto/Dropbox/Curso ML Ministrados/Curso ML Embrapii/Encontro 2")
insurance <- read.csv("insurance.csv", stringsAsFactors = TRUE)
hist(insurance$expenses)
table(insurance$region)
table(insurance$sex)
table(insurance$smoker)
cor(insurance[c("age", "bmi", "children", "expenses")])
ins_model <- lm(expenses ~ age + children + bmi + sex + smoker + region,
data = insurance)
ins_model
summary(ins_model)
insurance$age2 <- insurance$age^2
insurance$bmi30 <- ifelse(insurance$bmi >= 30, 1, 0)
ins_model2 <- lm(expenses ~ age + age2 + children + bmi + sex +
bmi30*smoker + region, data = insurance)
summary(ins_model2)
ins_model2 <- lm(expenses ~ age + age2 + children + bmi + sex +
bmi30*smoker +smoker + region, data = insurance)
summary(ins_model2)
ins_model2 <- lm(expenses ~ age + age2 + children + sex +
bmi30*smoker +smoker + region, data = insurance)
summary(ins_model2)
ins_model2 <- lm(expenses ~ age + age2 + children + sex + bmi +
bmi30*smoker + region, data = insurance)
summary(ins_model2)
setwd("C:/Users/neto/Dropbox/Curso ML Ministrados/Curso ML Embrapii/Material Curso PEIFSC/Encontro 2")
setwd("C:/Users/neto/Dropbox/Curso ML Ministrados/Curso ML Embrapii/Material Curso PEIFSC/Encontro 2")
teens <- read.csv("snsdata.csv")
View(teens)
table(teens$gender)
table(teens$gender, useNA = "ifany")
summary(teens$age)
teens$age <- ifelse(teens$age >= 13 & teens$age < 20,
teens$age, NA)
summary(teens$age)
teens$female <- ifelse(teens$gender == "F" &
!is.na(teens$gender), 1, 0)
teens$no_gender <- ifelse(is.na(teens$gender), 1, 0)
table(teens$gender, useNA = "ifany")
table(teens$female, useNA = "ifany")
table(teens$no_gender, useNA = "ifany")
ave_age <- ave(teens$age, teens$gradyear,
FUN = function(x) mean(x, na.rm = TRUE))
teens$age <- ifelse(is.na(teens$age), ave_age, teens$age)
summary(teens$age)
interests <- teens[5:40]
interests_z <- as.data.frame(lapply(interests, scale))
set.seed(2345)
teen_clusters <- kmeans(interests_z, 5)
teen_clusters$size
teen_clusters$centers
teens$cluster <- teen_clusters$cluster
teen_clusters <- kmeans(interests_z, 5)
teen_clusters$size
teen_clusters$centers
teens$cluster <- teen_clusters$cluster
teens$cluster <- teen_clusters$cluster
teens[1:5, c("cluster", "gender", "age", "friends")]
